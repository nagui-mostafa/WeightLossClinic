# Weight Loss Clinic Backend – Deployment & Operations Runbook

This document explains, in extreme detail, how the production backend is deployed
on AWS using a single EC2 instance plus Amazon RDS PostgreSQL. It covers every
command executed so far, the architecture, secrets management, seeding process,
ongoing deployments, migrations, troubleshooting, and what to change when
updating the `.env`. Anyone following this runbook should be able to recreate the
entire environment or operate on top of the existing setup confidently.

---
## 1. Current Architecture Overview

- **Region:** `us-east-1`
- **Compute:** 1× EC2 instance (`t4g.small`) acting as the application host
  - Instance ID: `i-0f9d8eab11737f436`
  - Public IP: `54.80.242.78`
  - Security Group: `sg-0e6bebd58a499e5f7`
  - Software installed:
    - Docker + docker-compose (manual binary) for running the NestJS container
    - nginx acting as reverse proxy on port 80 (plain HTTP for now)
    - AWS SSM agent (default) for remote commands without SSH
  - Data/Config directory: `/opt/weightloss`
    - `.env` file contains runtime env vars
    - `docker-compose.yml` defines the container service
    - `deploy.sh` automates pulling, optional migrations, and restart
    - `tsconfig.json` (copied from repo) so Prisma seed tool can run inside
    - Nginx configs in `/etc/nginx/nginx.conf` and `/etc/nginx/conf.d/weightloss.conf`
- **Database:** Amazon RDS PostgreSQL
  - Identifier: `weight-loss-db`
  - Instance class: `db.t4g.micro`
  - Endpoint: `weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com`
  - DB name: `weightloss`
  - Security Group: `sg-04b5eb936f15a7a07` (allows port 5432 only from EC2 SG)
- **Secrets storage:** AWS Systems Manager Parameter Store (free tier)
  - Path prefix: `/weightloss/prod/`
  - Parameters created:
    - `/weightloss/prod/DATABASE_URL`
    - `/weightloss/prod/JWT_ACCESS_SECRET`
    - `/weightloss/prod/JWT_REFRESH_SECRET`
    - `/weightloss/prod/MAIL_FROM`
    - `/weightloss/prod/MAIL_PASS`
    - `/weightloss/prod/MAIL_USER`
    - `/weightloss/prod/SEED_ADMIN_PASSWORD`
  - Each parameter is a SecureString (encrypted). Currently the EC2 host uses
    plain `.env`; future improvement is to load values from Parameter Store at
    deployment time so secrets aren’t stored in plain text on disk.
- **Logging:**
  - Application logs (piped from Docker) go to CloudWatch Logs `/weightloss/api`
  - nginx logs stay local (`/var/log/nginx`); optional to ship via CloudWatch agent
- **Cost profile:** ≈ $45/mo (EC2 + RDS + logs). No NAT, ALB, or App Runner charges.
  - Any "Amazon VPC" costs typically come from public IPv4 charges on the EC2 instance,
    NAT gateways, or VPC interface endpoints (none are intentionally provisioned here).

---
## 2. One-Time Provisioning Commands (already executed)

> These commands were run from the local machine, using AWS CLI with admin
> credentials. They generally don’t need to be rerun unless rebuilding from scratch.

### 2.1 RDS security tightening
```
aws ec2 revoke-security-group-ingress \
  --group-id sg-04b5eb936f15a7a07 \
  --protocol tcp --port 5432 --cidr 0.0.0.0/0 \
  --region us-east-1
```

### 2.2 Create EC2 security group (`weight-loss-ec2-sg`)
```
aws ec2 create-security-group \
  --group-name weight-loss-ec2-sg \
  --description "EC2 host for Weight Loss Clinic API" \
  --vpc-id vpc-0bda468753deca613 --region us-east-1
```
Add ingress rules (currently open to everyone; narrow to office IP ASAP):
```
# SSH (tighten to trusted IPs!)
aws ec2 authorize-security-group-ingress --group-id sg-0e6b... --protocol tcp --port 22 --cidr 0.0.0.0/0 --region us-east-1

# HTTP
aws ec2 authorize-security-group-ingress --group-id sg-0e6b... --protocol tcp --port 80 --cidr 0.0.0.0/0 --region us-east-1

# HTTPS (future use)
aws ec2 authorize-security-group-ingress --group-id sg-0e6b... --protocol tcp --port 443 --cidr 0.0.0.0/0 --region us-east-1
```

### 2.3 Allow EC2 SG to reach RDS
```
aws ec2 authorize-security-group-ingress \
  --group-id sg-04b5eb936f15a7a07 \
  --protocol tcp --port 5432 \
  --source-group sg-0e6bebd58a499e5f7 \
  --region us-east-1
```

### 2.4 Create SSH key (saved locally)
```
aws ec2 create-key-pair --key-name weight-loss-key \
  --query 'KeyMaterial' --output text --region us-east-1 > weight-loss-key.pem
chmod 400 weight-loss-key.pem
```

### 2.5 Launch EC2 instance
1. Get latest ARM AMI: `aws ssm get-parameter --name /aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-arm64 …`
2. Run instance (user data installs docker & compose):
```
aws ec2 run-instances \
  --image-id ami-0dda28e5df2d25176 \
  --instance-type t4g.small \
  --key-name weight-loss-key \
  --subnet-id subnet-0b427d557b3717d2c \
  --security-group-ids sg-0e6bebd58a499e5f7 \
  --user-data file://bootstrap.sh \
  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=weight-loss-api}]' \
  --region us-east-1
```
`bootstrap.sh` installed docker, docker-compose, git, CloudWatch agent.

### 2.6 Attach IAM role for SSM/ECR/logging
```
aws iam create-role --role-name WeightLossEC2SSMRole --assume-role-policy-document file://trust.json
aws iam attach-role-policy --role-name WeightLossEC2SSMRole --policy-arn arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
aws iam attach-role-policy --role-name WeightLossEC2SSMRole --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
aws iam attach-role-policy --role-name WeightLossEC2SSMRole --policy-arn arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
aws iam create-instance-profile --instance-profile-name WeightLossEC2SSMProfile
aws iam add-role-to-instance-profile --instance-profile-name WeightLossEC2SSMProfile --role-name WeightLossEC2SSMRole
aws ec2 associate-iam-instance-profile --instance-id i-0f9d8eab11737f436 --iam-instance-profile Name=WeightLossEC2SSMProfile
```
(Instance rebooted once to ensure SSM agent recognized the new profile.)

### 2.7 Auto-recovery alarm (free)
```
aws cloudwatch put-metric-alarm \
  --region us-east-1 \
  --alarm-name recover-i-0f9d8eab11737f436 \
  --metric-name StatusCheckFailed_System \
  --namespace AWS/EC2 \
  --statistic Minimum --period 60 --evaluation-periods 2 \
  --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold \
  --dimensions Name=InstanceId,Value=i-0f9d8eab11737f436 \
  --alarm-actions arn:aws:automate:us-east-1:ec2:recover
```

### 2.8 Install nginx + certbot
```
aws ssm send-command ... --parameters commands='["sudo dnf install -y nginx certbot python3-certbot-nginx", "sudo systemctl enable nginx"]'
```
Nginx config (current) lives in `/etc/nginx/conf.d/weightloss.conf`. Reverse proxies to 127.0.0.1:3000, exposes `/healthz`, and acts as default server on port 80. Main `/etc/nginx/nginx.conf` was simplified to only `include /etc/nginx/conf.d/*.conf;`.

### 2.9 Create CloudWatch Log group
```
aws logs create-log-group --log-group-name /weightloss/api --region us-east-1
```
Docker uses this log group via `awslogs` driver.

### 2.10 Delete unused App Runner secret
```
aws secretsmanager delete-secret --secret-id weight-loss-env --force-delete-without-recovery --region us-east-1
```

---
## 3. EC2 Host File Layout & Services

```
/opt/weightloss
├── .env                # Prod env vars (currently plain text; plan to load from SSM)
├── docker-compose.yml  # Single service mapping port 3000
├── deploy.sh           # Automates pull + optional migrate + restart
├── tsconfig.json       # Needed so `npm run db:seed` works inside container
└── (future) scripts, backups, etc.
```

### docker-compose.yml (current)
```
services:
  api:
    image: 851725402279.dkr.ecr.us-east-1.amazonaws.com/weight-loss-clinic-api:latest
    env_file:
      - /opt/weightloss/.env
    ports:
      - "3000:3000"
    restart: unless-stopped
    logging:
      driver: awslogs
      options:
        awslogs-group: /weightloss/api
        awslogs-region: us-east-1
        awslogs-stream: ec2
```

### deploy.sh (usage: `sudo /opt/weightloss/deploy.sh [migrate]`)
```
#!/bin/bash
set -euo pipefail

REGION="us-east-1"
ECR_IMAGE="851725402279.dkr.ecr.us-east-1.amazonaws.com/weight-loss-clinic-api:latest"
COMPOSE="/usr/local/bin/docker-compose"
ENV_FILE="/opt/weightloss/.env"

aws ecr get-login-password --region "$REGION" | sudo docker login --username AWS --password-stdin "${ECR_IMAGE%:*}"

sudo "$COMPOSE" pull

if [[ "${1:-}" == "migrate" ]]; then
  sudo docker run --rm --env-file "$ENV_FILE" "$ECR_IMAGE" npx prisma migrate deploy
fi

sudo "$COMPOSE" up -d
sudo docker image prune -f >/dev/null 2>&1
```

### scripts/full-deploy.sh (local helper to build/push/deploy via SSM)

Usage (common path):
```
scripts/full-deploy.sh --migrate --seed --smoke
# add --profile <aws-profile> if needed
```

Flags:
- `--migrate` run `prisma migrate deploy` on the host (via deploy.sh migrate)
- `--seed` run `npm run db:seed` on the host after deploy
- `--smoke` run health/ready/categories curl checks after deploy
- `--no-latest` skip tagging/pushing `:latest` (deploy.sh pulls :latest by default)
- `--tag <tag>` override image tag suffix (default = current git short hash)
- `--skip-build` assume image already built/pushed
- `--set-minio-policy` re-apply MinIO anonymous download policy

What it does:
1) Build image, tag with `<hash>` and `:latest` (unless `--no-latest`), push to ECR.
2) Run `/opt/weightloss/deploy.sh` on the EC2 host via SSM (with or without migrate).
3) Optionally seed and run smoke tests on the host.
4) Fails fast if the SSM command status is not Success.

Prereqs:
- Docker + AWS CLI on the local machine; AWS credentials/profile set.
- EC2 instance `i-0f9d8eab11737f436` managed by SSM.

Typical prod deploy for new code + migrations + seeds:
```
scripts/full-deploy.sh --migrate --seed --smoke
```

If you want to pin a specific tag and not use latest:
```
scripts/full-deploy.sh --tag mytag --no-latest --migrate --seed --smoke
# then update /opt/weightloss/docker-compose.yml on host to use mytag and rerun deploy.sh
```

### nginx reverse proxy
`/etc/nginx/conf.d/weightloss.conf`:
```
server {
    listen 80 default_server;
    server_name weightloss weightloss.local 54.80.242.78 localhost;
    client_max_body_size 25m;

    location /healthz {
        access_log off;
        default_type text/plain;
        return 200 'ok';
    }

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 60s;
        proxy_read_timeout 60s;
    }
}
```
To add HTTPS later, install certbot and run `sudo certbot --nginx -d yourdomain.com`. At present the site is HTTP-only.

---
## 4. Environment Variables & Secrets

### 4.1 Current `.env`
```
NODE_ENV=production
PORT=3000
DATABASE_URL=postgresql://weightloss_admin:TempPass123!@weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com:5432/weightloss?sslmode=require
JWT_ACCESS_SECRET=your-access-secret-key-change-in-production
JWT_REFRESH_SECRET=your-refresh-secret-key-change-in-production
ACCESS_TOKEN_TTL=3d
REFRESH_TOKEN_TTL=14d
PASSWORD_RESET_TOKEN_TTL=15m
EMAIL_VERIFICATION_TOKEN_TTL=24h
EMAIL_VERIFICATION_ENABLED=true
MAIL_HOST=smtp.gmail.com
MAIL_PORT=587
MAIL_USER=nagui.mostafa@gmail.com
MAIL_PASS=mlpkuqnyiufnkbgj
MAIL_FROM=nagui.mostafa@gmail.com
CORS_ORIGINS=http://13.c60.236.195:3000,http://localhost:3000,https://joeymed.com,http://localhost:5173,https://www.joeymed.com,https://app.joeymed.com
CLIENT_APP_URL=https://joeymed.com
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX=100
LOG_LEVEL=info
PROM_ENABLED=true
SEED_ADMIN_EMAIL=admin@weightlossclinic.com
SEED_ADMIN_PASSWORD=ChangeMeNow!123
OBJECT_STORAGE_DRIVER=minio
  OBJECT_STORAGE_ENDPOINT=http://172.17.0.1:9000
OBJECT_STORAGE_REGION=us-east-1
OBJECT_STORAGE_BUCKET=weight-loss-media
OBJECT_STORAGE_ACCESS_KEY=devaccess
OBJECT_STORAGE_SECRET_KEY=devsecret
OBJECT_STORAGE_FORCE_PATH_STYLE=true
OBJECT_STORAGE_USE_SSL=false
OBJECT_STORAGE_PUBLIC_BASE_URL=
```
**Action items:**
- Rotate DB password, JWT secrets, mail password. Update `.env` + Parameter Store simultaneously.
- Consider storing `.env` exclusively in Parameter Store and fetching it during deployment to avoid secrets on disk.
- Once S3 buckets are ready, swap the `OBJECT_STORAGE_*` values accordingly. Until then, keep the MinIO entries above so the API can build public URLs for product images.

### 4.1.1 PEM Key / SSH Access
- File: `weight-loss-key.pem`
- Location: stored on the operator's workstation (this repo root when created).
- Permissions: `chmod 400 weight-loss-key.pem` (already applied).
- Usage: `ssh -i weight-loss-key.pem ec2-user@54.80.242.78`
- Recommendation: keep the PEM in a secure password manager or secrets vault. If lost, you must create a new key pair and replace it on the EC2 instance.

### 4.2 Updating `.env` safely
1. Edit `/opt/weightloss/.env` (via SSM `aws ssm send-command ... "cat <<'EOF' > /opt/weightloss/.env" ...`).
2. Restart container: `sudo /opt/weightloss/deploy.sh` (no migrate) or `sudo docker-compose up -d`.
3. If the change is sensitive (password/JWT), also update Parameter Store so future deployments can read from there.

### 4.3 Parameter Store entries (for reference)
```
aws ssm describe-parameters --parameter-filters Key=Path,Option=Recursive,Values=/weightloss/prod --region us-east-1
```
Each entry can be retrieved via `aws ssm get-parameter --with-decryption` or in automation.

### 4.4 Temporary MinIO setup (acts like S3)

Until the production S3 buckets exist, we run MinIO directly on the EC2 host and point the API at it via the `OBJECT_STORAGE_*` vars. Full recipe:

1. **Start MinIO** (run once over SSH/SSM):
   ```bash
   sudo mkdir -p /opt/minio/data
   sudo docker run -d --name minio \
     -p 9000:9000 -p 9001:9001 \
     -e MINIO_ROOT_USER=devaccess \
     -e MINIO_ROOT_PASSWORD=devsecret \
     -v /opt/minio/data:/data \
     --restart unless-stopped \
     quay.io/minio/minio server /data --console-address ":9001"
   ```
   - Port 9000 serves S3-compatible traffic.
   - Port 9001 exposes the MinIO console (reach it via `ssh -L9001:127.0.0.1:9001 ec2-user@54.80.242.78 -i weight-loss-key.pem`).

2. **Configure the `mc` client & bucket**
   ```bash
   sudo docker run --rm --network host --entrypoint /bin/sh minio/mc -c \
     "mc alias set local http://127.0.0.1:9000 devaccess devsecret && \
       mc mb -p local/weight-loss-media"
   ```
   After this, any object placed under `/opt/minio/data/weight-loss-media/...` instantly becomes available via the bucket.

3. **Wire env vars into the app** (already present in `/opt/weightloss/.env`):
   ```
   OBJECT_STORAGE_DRIVER=minio
   OBJECT_STORAGE_ENDPOINT=http://127.0.0.1:9000
   OBJECT_STORAGE_REGION=us-east-1
   OBJECT_STORAGE_BUCKET=weight-loss-media
   OBJECT_STORAGE_ACCESS_KEY=devaccess
   OBJECT_STORAGE_SECRET_KEY=devsecret
   OBJECT_STORAGE_FORCE_PATH_STYLE=true
   OBJECT_STORAGE_USE_SSL=false
   OBJECT_STORAGE_PUBLIC_BASE_URL=https://api.joeymed.com/minio/{bucket}
   ```
   Redeploy (`sudo ./deploy.sh`) any time the env file changes so NestJS picks up the new values. Remember the Nest container cannot reach services bound to `127.0.0.1` on the host; use the Docker bridge IP (`172.17.0.1` on this box) so uploads succeed. You can confirm the address with `ip addr show docker0` if it ever changes.

4. **Expose MinIO via nginx** by using the repo’s `weightloss-nginx.conf` (shipped under `weightloss-nginx.conf`). The important stanza:
   ```nginx
   location /minio/ {
       proxy_pass http://127.0.0.1:9000/;
       proxy_set_header Host $host;
       proxy_set_header X-Real-IP $remote_addr;
       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
       proxy_set_header X-Forwarded-Proto $scheme;
   }
   ```
   Deploy it via `scp weightloss-nginx.conf` → copy into `/etc/nginx/conf.d/weightloss.conf` → `sudo nginx -t && sudo systemctl reload nginx`.

5. **Upload real assets** either with the MinIO console (tunnel into port 9001) or via CLI:
   ```bash
   sudo docker run --rm --network host --entrypoint /bin/sh minio/mc -c \
     "mc alias set local http://127.0.0.1:9000 devaccess devsecret && \
       mc cp /tmp/hero.png local/weight-loss-media/weight-loss/products/glp1-core/hero.png"
   ```

6. **Security**
   - Leave ports 9000/9001 closed on the EC2 security group; only nginx proxies `/minio/` externally.
   - Rotate `MINIO_ROOT_PASSWORD` and the `.env` values whenever administrators change.
   - Keep daily snapshots of `/opt/minio/data` or replicate to S3 if you add real PHI.
   - Enable read-only public access through the API proxy (run once after provisioning or after recreating the bucket):
      ```
      sudo docker run --rm --network host --entrypoint /bin/sh minio/mc -c \
        "mc alias set local http://127.0.0.1:9000 devaccess devsecret && \
         mc anonymous set download local/weight-loss-media"
      ```

7. **Graduating to S3/CDN**
   - Create an S3 bucket (e.g., `cdn-weight-loss-media`) and upload assets.
   - Set `OBJECT_STORAGE_DRIVER=s3`, `OBJECT_STORAGE_BUCKET=<bucket>`, AWS access keys, and optionally `OBJECT_STORAGE_PUBLIC_BASE_URL=https://cdn.example.com/{bucket}`.
   - Stop/remove the MinIO container (`sudo docker rm -f minio`), redeploy the app, and remove the `/minio/` nginx stanza once traffic is fully on S3.

**Pros/Cons of the current MinIO-on-EC2 approach**

- ✅ Zero AWS storage cost during pilot; data never leaves the private host.
- ✅ No IAM work required; everything is local credentials.
- ❌ Single-point-of-failure: if the EC2 instance dies, images go with it unless you back up `/opt/minio/data`.
- ❌ Images are served through the API host, so large responses increase CPU/bandwidth on the main server.
- ❌ Not multi-AZ; no lifecycle policies or storage tiers.

**Next steps for S3 migration**

1. Provision an S3 bucket (and optional CloudFront distribution) in `us-east-1`.
2. Create an IAM user/role limited to that bucket; store keys in Parameter Store.
3. Update `.env`/Parameter Store with the S3 driver details, redeploy, and remove MinIO.
4. Update nginx to drop `/minio/` once all URLs point to S3/CDN.

---
## 5. Seeding & Data Reset

**Command used to seed current production DB (already executed):**
```
sudo docker run --rm \
  --env-file /opt/weightloss/.env \
  -v /opt/weightloss/tsconfig.json:/app/tsconfig.json \
  851725402279.dkr.ecr.us-east-1.amazonaws.com/weight-loss-clinic-api:latest \
  npm run db:seed
```
This resets the database, so **run it only on fresh instances** (never on a live DB with real users). Output provided admin + patient demo credentials.

For staging or future resets, copy `tsconfig.json` from repo if missing. Without the volume mount, `ts-node` complains about unknown `.ts` extension.

---
## 6. Future Deployments (code changes)

1. **Develop & test locally.** Commit code + Prisma migrations.
2. **Build & push image** (from local machine with AWS CLI creds). Recommended:
   ```
   scripts/full-deploy.sh --migrate --set-minio-policy
   ```
   Flags:
   - `--skip-build` (if image already built/pushed)
   - `--tag <tag>` to override the default git-hash suffix
   - `--migrate` to run `prisma migrate deploy` on EC2
   - `--set-minio-policy` to re-apply the anonymous read policy via `mc`
3. **Deploy on EC2**
   - Remote in via SSM: `aws ssm start-session --target i-0f9d8eab11737f436`
   - Run deployment script (include `migrate` if schema changed):
     - Without migrations: `sudo /opt/weightloss/deploy.sh`
     - With migrations: `sudo /opt/weightloss/deploy.sh migrate`
       - Script does: ECR login → `docker-compose pull` → (optional) `npx prisma migrate deploy` inside container → `docker-compose up -d` → prune old images.
4. **Verify**
 - `curl http://localhost/v1/ready` (via SSM) or `curl http://54.80.242.78/v1/ready`
 - `curl -I http://localhost/minio/weight-loss-media/<object>` (ensures the nginx → MinIO proxy works)
 - Check CloudWatch log group `/weightloss/api` or stream logs locally (`sudo docker logs -f weightloss-api-1`).

**Rollback:**
- If new image is broken, rerun `docker-compose up -d` with a pinned previous tag. Keep older image tags in ECR for safety.

### 6.1 Weight-loss products rollout (November 2025)

Follow this checklist the first time you want the new products table + API live in production:

1. **Deploy the new image with migration**
   ```
   sudo /opt/weightloss/deploy.sh migrate
   ```
   This pulls the image, runs `prisma migrate deploy` (creating `weight_loss_products`), and restarts the container.

2. **Seed the catalog (idempotent upserts)**
   Run the following once. It only touches the `weight_loss_products` table and can be rerun safely.
   ```
   export PGPASSWORD='TempPass123!'
   psql "postgresql://weightloss_admin:TempPass123!@weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com:5432/weightloss?sslmode=require" <<'SQL'
   INSERT INTO weight_loss_products
     (token, name, href, "hrefForm", "oldPrice", price, popular, "inStock", badge, description, shipping, instructions, "sideEffects", features, "whyChoose", plan, question, "howItWorks", images, metadata)
   VALUES
     (
       'glp1-core-plan',
       'GLP-1 Core - Injection',
       '/weight-loss/glp1-core-plan',
       'wLinkForm',
       279,
       199,
       true,
       true,
       'Clinician-guided GLP-1 program (Semaglutide)',
       'A GLP-1 core plan (Semaglutide) designed to support steady weight loss, appetite control, and metabolic balance with weekly injections.',
       'Ships in 1-2 days - Free delivery over $40',
       'Inject once weekly as directed by your provider. Follow the titration schedule and do not exceed the prescribed dose.',
       'Possible nausea, GI upset, or headache. Effects are usually mild and temporary. Contact your provider if severe.',
       ARRAY['GLP-1 support with weekly dosing','Focus on appetite and satiety','Provider-guided titration schedule'],
       '[
         {"title":"Clinician-guided","excerpt":"Structured plan with check-ins","imgSrc":"/images/weight-loss/products/1.jpg"},
         {"title":"Appetite control","excerpt":"Helps reduce cravings","imgSrc":"/images/weight-loss/products/2.jpg"},
         {"title":"Steady progress","excerpt":"Built for sustainable loss","imgSrc":"/images/weight-loss/products/3.jpg"}
       ]'::jsonb,
       '[
         {"id":"1","title":"4 Week","price":199,"oldPrice":279,"href":"https://pay.joeymed.com/b/fZueV6cY7eXLfJee337wA0n"},
         {"id":"2","title":"8 Weeks","price":299,"oldPrice":440,"href":"https://pay.joeymed.com/b/dRmeV68HRcPDbsY0cd7wA0t"},
         {"id":"3","title":"12 Week Elite","price":399,"oldPrice":599,"href":"https://pay.joeymed.com/b/9B69AM5vFcPD0Ok9MN7wA0u"}
       ]'::jsonb,
       '[
         {"title":"What is this plan?","description":"A weekly GLP-1 program designed to support steady weight loss with provider oversight and lifestyle guidance."},
         {"title":"How do I use it?","description":"Inject once per week as instructed. Stay consistent with your dosing day and follow your nutrition plan."},
         {"title":"Side effects?","description":"Mild nausea or GI upset can occur and often fades. Seek help if symptoms are severe or persistent."}
       ]'::jsonb,
       '[
         {"step":1,"title":"Start weekly dosing","description":"Begin with a starter dose and follow your titration plan."},
         {"step":2,"title":"Support habits","description":"Pair with nutrition, hydration, and daily movement."},
         {"step":3,"title":"Track results","description":"Review progress with your provider and adjust as needed."}
       ]'::jsonb,
       '[
         {"id":"glp1-core-plan-hero","bucket":"weight-loss-media","objectKey":"weight-loss/products/glp1-core/hero.png","altText":"GLP-1 Core hero art","fallbackUrl":"/images/weight-loss/products/GLP-1 Core.png","variant":"hero"},
         {"id":"glp1-core-plan-alt-1","bucket":"weight-loss-media","objectKey":"weight-loss/products/glp1-core/detail-1.png","altText":"GLP-1 Core detail 1","fallbackUrl":"/images/weight-loss/products/GLP-1 Core.png","variant":"detail"},
         {"id":"glp1-core-plan-alt-2","bucket":"weight-loss-media","objectKey":"weight-loss/products/glp1-core/detail-2.png","altText":"GLP-1 Core detail 2","fallbackUrl":"/images/weight-loss/products/GLP-1 Core.png","variant":"detail"}
       ]'::jsonb,
       '{"category":"glp-1","displayOrder":1}'::jsonb
     )
   ON CONFLICT (token) DO UPDATE SET
     name = EXCLUDED.name,
     href = EXCLUDED.href,
     "hrefForm" = EXCLUDED."hrefForm",
     "oldPrice" = EXCLUDED."oldPrice",
     price = EXCLUDED.price,
     popular = EXCLUDED.popular,
     "inStock" = EXCLUDED."inStock",
     badge = EXCLUDED.badge,
     description = EXCLUDED.description,
     shipping = EXCLUDED.shipping,
     instructions = EXCLUDED.instructions,
     "sideEffects" = EXCLUDED."sideEffects",
     features = EXCLUDED.features,
     "whyChoose" = EXCLUDED."whyChoose",
     plan = EXCLUDED.plan,
     question = EXCLUDED.question,
     "howItWorks" = EXCLUDED."howItWorks",
     images = EXCLUDED.images,
     metadata = EXCLUDED.metadata;

   INSERT INTO weight_loss_products
     (token, name, href, "hrefForm", "oldPrice", price, popular, "inStock", badge, description, shipping, instructions, "sideEffects", features, "whyChoose", plan, question, "howItWorks", images, metadata)
   VALUES
     (
       'glp1-plus-core-plan',
       'GLP-1 Plus Core - Injection',
       '/weight-loss/glp1-plus-core-plan',
       'wLinkForm',
       399,
       279,
       false,
       true,
       'Enhanced guidance and follow-ups (Tirzepatide)',
       'An enhanced GLP-1 (Tirzepatide) plan with weekly injections, added provider follow-ups, and lifestyle coaching support for stronger adherence.',
       'Ships in 1-2 days - Free delivery over $40',
       'Inject weekly on a consistent day. Attend scheduled check-ins and follow your titration and nutrition plan.',
       'Potential nausea, stomach upset, or headache. Typically transient; contact your provider if persistent or severe.',
       ARRAY['Weekly GLP-1 injections','Extra provider follow-ups','Lifestyle and adherence support'],
       '[
         {"title":"More support","excerpt":"Added check-ins for accountability","imgSrc":"/images/weight-loss/products/1.jpg"},
         {"title":"Personalized tweaks","excerpt":"Dosing adjusted to your response","imgSrc":"/images/weight-loss/products/2.jpg"},
         {"title":"Clear roadmap","excerpt":"Structured plan to stay on track","imgSrc":"/images/weight-loss/products/3.jpg"}
       ]'::jsonb,
       '[
         {"id":"5","title":"4 Weeks","price":279,"oldPrice":379,"href":"https://pay.joeymed.com/b/eVq6oA9LVeXL68E1gh7wA0p"},
         {"id":"6","title":"8 Weeks","price":399,"oldPrice":458,"href":"https://pay.joeymed.com/b/aFa6oA6zJ8zn2Ws4st7wA0v"},
         {"id":"7","title":"12 Week Elite","price":499,"oldPrice":589,"href":"https://pay.joeymed.com/b/aFacMYbU36rf68E5wx7wA0A"}
       ]'::jsonb,
       '[
         {"title":"What is different vs Core?","description":"You receive more frequent provider follow-ups and added coaching support to help maintain momentum."},
         {"title":"How do I get started?","description":"Complete your intake, get approved, and begin weekly injections with an adherence plan and check-ins."},
         {"title":"Any diet rules?","description":"Focus on protein, hydration, and fiber-rich foods. Your provider may share a simple weekly nutrition target."}
       ]'::jsonb,
       '[
         {"step":1,"title":"Intake and approval","description":"Complete intake and provider review."},
         {"step":2,"title":"Weekly dosing","description":"Follow your injection plus titration schedule."},
         {"step":3,"title":"Check-ins","description":"Use follow-ups to fine-tune and stay consistent."}
       ]'::jsonb,
       '[
         {"id":"glp1-plus-core-hero","bucket":"weight-loss-media","objectKey":"weight-loss/products/glp1-plus-core/hero.png","altText":"GLP-1 Plus Core hero art","fallbackUrl":"/images/weight-loss/products/GLP-1 Plus Core.png","variant":"hero"},
         {"id":"glp1-plus-core-alt-1","bucket":"weight-loss-media","objectKey":"weight-loss/products/glp1-plus-core/detail-1.png","altText":"GLP-1 Plus Core detail 1","fallbackUrl":"/images/weight-loss/products/GLP-1 Plus Core.png","variant":"detail"}
       ]'::jsonb,
       '{"category":"glp-1","displayOrder":2}'::jsonb
     )
   ON CONFLICT (token) DO UPDATE SET
     name = EXCLUDED.name,
     href = EXCLUDED.href,
     "hrefForm" = EXCLUDED."hrefForm",
     "oldPrice" = EXCLUDED."oldPrice",
     price = EXCLUDED.price,
     popular = EXCLUDED.popular,
     "inStock" = EXCLUDED."inStock",
     badge = EXCLUDED.badge,
     description = EXCLUDED.description,
     shipping = EXCLUDED.shipping,
     instructions = EXCLUDED.instructions,
     "sideEffects" = EXCLUDED."sideEffects",
     features = EXCLUDED.features,
     "whyChoose" = EXCLUDED."whyChoose",
     plan = EXCLUDED.plan,
     question = EXCLUDED.question,
     "howItWorks" = EXCLUDED."howItWorks",
     images = EXCLUDED.images,
     metadata = EXCLUDED.metadata;

   INSERT INTO weight_loss_products
     (token, name, href, "hrefForm", "oldPrice", price, popular, "inStock", badge, description, shipping, instructions, "sideEffects", features, "whyChoose", plan, question, "howItWorks", images, metadata)
   VALUES
     (
       'lipo-mic-ultraburn',
       'Lipo MIC UltraBurn - Injection',
       '/weight-loss/lipo-mic-ultraburn',
       'wLinkForm',
       199,
       89,
       false,
       true,
       'Metabolism and energy support',
       'A Lipo MIC blend to support fat metabolism and energy alongside your nutrition and movement plan.',
       'Ships in 1-2 days - Free delivery over $40',
       'Use as directed by your provider. Follow the recommended schedule and pair with diet and activity guidance.',
       'Generally well-tolerated; mild injection-site discomfort possible. Contact your provider if you experience unusual symptoms.',
       ARRAY['Lipo MIC (lipotropics) blend','Supports fat metabolism and energy','Provider-guided schedule'],
       '[
         {"title":"Metabolic nudge","excerpt":"Designed to complement weight efforts","imgSrc":"/images/weight-loss/products/1.jpg"},
         {"title":"Convenient cadence","excerpt":"Simple provider-guided schedule","imgSrc":"/images/weight-loss/products/2.jpg"},
         {"title":"Pairs with GLP-1","excerpt":"Use alongside diet and movement","imgSrc":"/images/weight-loss/products/3.jpg"}
       ]'::jsonb,
       '[
         {"id":"5","title":"4 Weeks","price":60,"oldPrice":120,"href":"https://pay.joeymed.com/b/4gM7sEaPZg1P40waQR7wA0w"},
         {"id":"6","title":"8 Weeks","price":100,"oldPrice":160,"href":"https://pay.joeymed.com/b/28E28kf6fbLz68Egbb7wA0x"},
         {"id":"7","title":"12 Week Elite","price":120,"oldPrice":200,"href":"https://pay.joeymed.com/b/00w5kw3nxcPD9kQ1gh7wA0y"}
       ]'::jsonb,
       '[
         {"title":"What is Lipo MIC?","description":"A combination of lipotropic compounds used to support fat metabolism and energy as part of a broader plan."},
         {"title":"How is it used?","description":"Administer on the schedule provided by your clinician. Keep consistent nutrition, hydration, and activity."},
        {"title":"Can I combine with GLP-1?","description":"Often used alongside lifestyle and other therapies. Always follow your provider''s guidance."}
       ]'::jsonb,
       '[
         {"step":1,"title":"Provider plan","description":"Confirm your dosing cadence and goals."},
         {"step":2,"title":"Stay consistent","description":"Follow the schedule and log how you feel."},
         {"step":3,"title":"Review and adjust","description":"Share progress; your plan can be refined."}
       ]'::jsonb,
       '[
         {"id":"lipo-ultraburn-hero","bucket":"weight-loss-media","objectKey":"weight-loss/products/lipo-mic-ultraburn/hero.png","altText":"Lipo MIC UltraBurn hero art","fallbackUrl":"/images/weight-loss/products/Lipo MIC Ultraburn.png","variant":"hero"}
       ]'::jsonb,
       '{"category":"mic","displayOrder":3}'::jsonb
     )
   ON CONFLICT (token) DO UPDATE SET
     name = EXCLUDED.name,
     href = EXCLUDED.href,
     "hrefForm" = EXCLUDED."hrefForm",
     "oldPrice" = EXCLUDED."oldPrice",
     price = EXCLUDED.price,
     popular = EXCLUDED.popular,
     "inStock" = EXCLUDED."inStock",
     badge = EXCLUDED.badge,
     description = EXCLUDED.description,
     shipping = EXCLUDED.shipping,
     instructions = EXCLUDED.instructions,
     "sideEffects" = EXCLUDED."sideEffects",
     features = EXCLUDED.features,
     "whyChoose" = EXCLUDED."whyChoose",
     plan = EXCLUDED.plan,
     question = EXCLUDED.question,
     "howItWorks" = EXCLUDED."howItWorks",
     images = EXCLUDED.images,
     metadata = EXCLUDED.metadata;
   SQL
   ```

3. **Verify endpoints**
   ```
   curl -s https://api.joeymed.com/v1/weight-loss-products | jq '.[].token'
   curl -s https://api.joeymed.com/v1/weight-loss-products/glp1-core-plan | jq '.name'
   ```
   Both the list and detail endpoints are public. POST/PUT/DELETE require an admin JWT (`Authorization: Bearer <token>`).

4. **Check MinIO assets** – ensure the image object keys referenced above exist in the `weight-loss-media` bucket (see section 4.4). If not, upload placeholder PNGs so the frontend does not render broken links.

### 6.2 Editing catalog entries via Swagger or Postman

The `weight-loss-products` endpoints live under `https://api.joeymed.com/docs` → “weight-loss-products”. Mutations require an admin JWT.

1. **Obtain an admin token** via the Auth → `/v1/auth/login` endpoint, or reuse the credential from the seed data (`admin@weightlossclinic.com / 12345678` by default). Copy the `accessToken`.
2. **Swagger UI**
   - Open `https://api.joeymed.com/docs`, click the padlock icon, and enter `Bearer <token>`.
   - Expand `PUT /v1/weight-loss-products/{token}`. Example body to swap a hero image:
     ```json
     {
       "images": [
         {
           "id": "glp1-core-plan-hero",
           "bucket": "weight-loss-media",
           "objectKey": "weight-loss/products/glp1-core/new-hero.png",
           "fallbackUrl": "/images/weight-loss/products/GLP-1 Core.png",
           "variant": "hero"
         }
       ]
     }
     ```
   - Execute the call; the response will include the normalized payload plus the computed `url`.
3. **Postman**
   - Method: `PUT https://api.joeymed.com/v1/weight-loss-products/glp1-core-plan`
   - Headers: `Authorization: Bearer <token>`, `Content-Type: application/json`.
   - Body: same JSON as above.
4. **Upload the matching asset** to MinIO before/after the API call (section 4.4 step 5).
5. **Smoke tests**
   ```bash
   # List all products
   curl -s https://api.joeymed.com/v1/weight-loss-products | jq '.[].token'

   # Fetch detail + confirm hero URL
   curl -s https://api.joeymed.com/v1/weight-loss-products/glp1-core-plan | jq '.images'

   # Hit the proxied MinIO object (returns 404 until an image is uploaded)
   curl -I https://api.joeymed.com/minio/weight-loss-media/weight-loss/products/glp1-core/new-hero.png
   ```

If a request fails, inspect `sudo docker logs weightloss-api-1` on EC2 or use CloudWatch `/weightloss/api`.

### 6.3 Groupon QA coupons & mock flag

The Groupon integration now has two deployment-time tasks:

1. **Disable the mock handler in prod** – run the deploy helper with `--set-var GROUPON_USE_MOCK=false` to surgically flip the flag inside `/opt/weightloss/.env` without re-uploading the entire file:
   ```
   scripts/full-deploy.sh --set-var GROUPON_USE_MOCK=false
   ```
   Combine this with `--update-env --env-file prod.env` if several values changed at once.

2. **Seed the QA vouchers without touching real data** – use the new flag to run the targeted Prisma script inside the freshly deployed image:
   ```
   scripts/full-deploy.sh --seed-groupon-tests
   ```
   Under the hood this executes `npx ts-node -r tsconfig-paths/register scripts/seed-groupon-test-codes.ts`, which performs idempotent upserts for `TFZ3D9F9`, `MZXBDKNY`, `FQ7XEUMF`, `WXCRVAE7`, and `Q62DUNE5` with the `groupon:test` metadata (planWeeks=0, productToken=test). Run it any time the QA coupons need to be reloaded; duplicates are ignored.

3. **Typical end-to-end deploy** – build/push, flip the env var, migrate (if needed), and seed the QA coupons in one shot:
   ```
   scripts/full-deploy.sh --migrate --set-var GROUPON_USE_MOCK=false --seed-groupon-tests --smoke
   ```
   The script still supports `--seed` (full database reset) for staging only; use `--seed-groupon-tests` in production to avoid wiping live data.

---
## 7. Database Migrations (with live data)

Whenever schema changes:
1. Develop migration locally (`npx prisma migrate dev --name ...`). Commit migration SQL.
2. Deploy new image.
3. On EC2, run `npx prisma migrate deploy` (script supports this via `deploy.sh migrate`).
   - Do **not** run `prisma migrate reset`; it wipes data.
4. Verify with `prisma migrate status` (optional) or by checking new tables/columns.
5. If migration fails, fix SQL and redeploy; do not continue running the old app against partially migrated schema.

**Backups:** RDS already takes daily automated backups (1-day retention). Increase retention to 7–14 days: `aws rds modify-db-instance --db-instance-identifier weight-loss-db --backup-retention-period 7 --apply-immediately`.

---
## 8. Accessing the Database

For WebStorm or psql, use:
- Host: `weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com`
- Port: `5432`
- Database: `weightloss`
- User: `weightloss_admin`
- Password: `TempPass123!` (change soon!)
- SSL mode: `require`

Example psql command:
```
psql "postgresql://weightloss_admin:TempPass123!@weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com:5432/weightloss?sslmode=require"
```

### 8.1 Secure local access via SSM tunnel
- Install the AWS Session Manager plugin.
- Start a port forward (keep the terminal open while connected):
  ```
  aws ssm start-session \
    --target i-0f9d8eab11737f436 \
    --document-name AWS-StartPortForwardingSessionToRemoteHost \
    --parameters '{"host":["weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com"],"portNumber":["5432"],"localPortNumber":["5433"]}'
  ```
- In WebStorm or psql, point to `localhost:5433` (SSL disabled):
  ```
  psql "postgresql://weightloss_admin:<password>@localhost:5433/weightloss"
  ```
- Hit Ctrl+C to close the tunnel when done. This avoids opening security-group rules for each developer IP.

---
## 9. HTTP/HTTPS & DNS

Currently the API is accessible at both `http://54.80.242.78` and the HTTPS endpoint `https://api.joeymed.com`.

Steps already performed (no cost):
1. **DNS** – Added Route 53 record `api.joeymed.com` → `54.80.242.78`:
   ```
   aws route53 change-resource-record-sets --hosted-zone-id Z0723136258GJLMYWMAPS --change-batch '{
     "Changes": [{
       "Action": "UPSERT",
       "ResourceRecordSet": {
         "Name": "api.joeymed.com.",
         "Type": "A",
         "TTL": 60,
         "ResourceRecords": [{"Value": "54.80.242.78"}]
       }
     }]
   }'
   ```
2. **Let’s Encrypt certificate via Certbot (free)**
   ```
   sudo certbot --nginx -d api.joeymed.com --non-interactive --agree-tos -m nagui.mostafa@gmail.com
   ```
   - Cert files: `/etc/letsencrypt/live/api.joeymed.com/`
   - nginx config automatically updated by Certbot to force HTTPS.
   - Auto-renewal cron/systemd timer is in place.

Now the canonical API base URL is **`https://api.joeymed.com`**. HTTP on `54.80.242.78` still works but browsers should use HTTPS.

If you ever rebuild:
1. Recreate the A record for the new EC2 IP.
2. Re-run the certbot command.
3. Certs renew automatically every ~60 days; verify with `sudo certbot renew --dry-run`.

If you later prefer an Application Load Balancer (for zero-downtime deploys), you can move nginx behind ALB and share the load balancer across services. That adds ~$20/mo.

### 9.1 Frontend (AWS Amplify Next.js) Integration
- Current Amplify site: `https://joeymed.com/`
- Backend HTTPS URL: `https://api.joeymed.com`
- Frontend environment/config should point to that base (e.g., `NEXT_PUBLIC_API_URL=https://api.joeymed.com`). No more mixed-content warnings because both sides use HTTPS.
- CORS already allows `https://joeymed.com` and `https://app.joeymed.com`. If you add more domains, append them to `CORS_ORIGINS` in `.env` and redeploy.
- If Amplify needs WebSocket/SSE, ensure nginx proxies those paths as well (currently everything under `/` is proxied to NestJS).

### 9.2 Frontend ↔ API ↔ MinIO flow (weight-loss products)

1. **Environment variables in Amplify**
   - `NEXT_PUBLIC_API_URL=https://api.joeymed.com/v1`
   - Optional: `NEXT_PUBLIC_PRODUCTS_TAGLINE`, etc.

   > Tip: keep staging/local builds pointed at `http://localhost:3333/v1` so you can test uploads against your laptop + local MinIO before shipping new assets to prod.

2. **Fetching data (Next.js example)**
  ```ts
  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/weight-loss-products`, {
    cache: 'no-store',
  });
  const products: ProductResponseDto[] = await res.json();
  ```
  Each product already includes normalized `plan`, `question`, `howItWorks`, `images`, and `whyChoose` arrays.

3. **Rendering images in Next.js**
  ```tsx
  {product.images.map((image) => (
    <Image
      key={image.id}
      src={image.url ?? image.fallbackUrl ?? '/placeholder.png'}
      alt={image.altText ?? product.name}
      width={640}
      height={640}
    />
  ))}
  ```
  - Display `product.whyChoose` artwork with the provided `imgSrc` URLs (these are now generated automatically when the admin uploads a file).
  - When MinIO hosts the asset, `url` looks like `https://api.joeymed.com/minio/weight-loss-media/...` thanks to `OBJECT_STORAGE_PUBLIC_BASE_URL`. Switching to S3/CDN only requires changing the env vars.
   - All URLs are absolute, so Next.js does not need signed URLs or presigned requests; the nginx proxy handles access control.
   - The `images` array may be empty; always provide a fallback (placeholder art) to avoid runtime errors during SSR.

4. **Admin tooling (mini-admin or Swagger)**
  - The `PUT /v1/weight-loss-products/:token` endpoint now accepts either `application/json` (when only metadata changes) or `multipart/form-data` with:
    - A `payload` field that contains the JSON body shaped like `UpdateWeightLossProductDto`.
    - One binary field per image you want to upload. Set `images[].uploadField` (or `whyChoose[].imgSrcUploadField`) in the JSON to the matching form-data field name.
  - Our mini-admin UI (running on `http://localhost:3000`) previews product thumbnails, lets you add more `images[]` entries, and lets you upload brand-new files for both `images[]` and the `whyChoose[]` cards. Every successful upload is pushed to MinIO via the backend service and the resulting public URL is persisted automatically.
    - Hero images: ensure the `id` remains `hero` so the backend overwrites the previous file (`weight-loss/products/<token>/hero.<ext>`). This avoids orphaned files.
    - Why choose cards: each row can either supply an `imgSrc` (remote CDN asset) or attach a file; when a file is uploaded the API generates a stable key under `weight-loss/products/<token>/why-choose/<slug>.jpeg`.
  - On the frontend, simply use the URLs returned by the API; no additional signing logic is required. During SSR, prefer `next/image` with `unoptimized` or configure the remote pattern to allow `api.joeymed.com`.
  - For cache busting in Next.js, append `?updatedAt=${product.updatedAt}` when rendering `<Image>` if you’re concerned about CDN caching stale heroes.

5. **Testing checklist**
  - `curl https://api.joeymed.com/v1/weight-loss-products | jq '.[].token'`
  - `curl https://api.joeymed.com/minio/weight-loss-media/...` (should return 200 if the object exists, 404 otherwise).
  - Upload a test image via the mini-admin tool; verify the response includes the new `url` and the image is reachable via `https://api.joeymed.com/minio/...`.
  - In Amplify preview builds, ensure the Network tab shows 200 responses from `https://api.joeymed.com` and `https://api.joeymed.com/minio/...`.

---
## 10. SSH Hardening

Right now port 22 on `sg-0e6bebd58a499e5f7` is open to the world. Recommended change:
```
aws ec2 revoke-security-group-ingress --group-id sg-0e6bebd58a499e5f7 --protocol tcp --port 22 --cidr 0.0.0.0/0 --region us-east-1
aws ec2 authorize-security-group-ingress --group-id sg-0e6bebd58a499e5f7 --protocol tcp --port 22 --cidr <YOUR_STATIC_IP>/32 --region us-east-1
```
Or remove SSH entirely and use Session Manager for interactive shells.

---
## 11. Troubleshooting Cheat Sheet

- **SSH/HTTP inaccessible:** Check EC2 SG rules, confirm instance is `running`, and verify nginx/dcoker service status via SSM: `sudo systemctl status nginx`, `sudo docker ps`.
- **503 or no response at /v1/ready:** ensure container is running (`docker ps`), check CloudWatch logs for errors, verify RDS reachable.
- **Seed script errors:** mount tsconfig (`-v /opt/weightloss/tsconfig.json:/app/tsconfig.json`), ensure `.env` has correct DB credentials.
- **Prisma migrate fails:** inspect `/opt/weightloss/prisma/migrations/*` inside container. Use `npx prisma migrate resolve --rolled-back ...` if needed, but proceed carefully.
- **Log stream permission errors:** ensure EC2 IAM role has `CloudWatchLogsFullAccess` (already attached).
- **Out of disk:** prune unused images (`sudo docker image prune -af`), consider increasing root EBS volume (default 8 GB).

---
## 12. Rebuilding Everything from Scratch (Disaster Recovery)

1. Terminate EC2 instance (optional if unusable).
2. Re-run sections 2.1–2.10 to recreate SGs, key pair, instance, IAM role, nginx, etc.
3. Attach the ECR repo + Parameter Store values remain in AWS; no need to re-create unless intentionally deleted.
4. Deploy code (`docker-compose pull && up -d`).
5. Run `deploy.sh migrate` followed by `deploy.sh` to ensure schema is current.
6. *Only if needed* run the seed command (this wipes DB!).
7. Reconfigure DNS/TLS if IP changed.

---
## 13. Outstanding TODOs / Future Enhancements

- Restrict SSH to static IP or remove entirely; rely on SSM.
- Switch secrets loading to Parameter Store (e.g., using AWS CLI or ssm-agent inside `deploy.sh`).
- Enable HTTPS via Let’s Encrypt + nginx or ACM + ALB.
- Increase RDS backup retention and enable Performance Insights.
- Add CloudWatch alarms for high CPU, low disk, HTTP 5xx, etc.
- Consider Infrastructure-as-Code (Terraform or CDK) to recreate the stack automatically.

---
## 14. Quick Reference: Common Commands

**Start a shell on EC2 via Session Manager**
```
aws ssm start-session --target i-0f9d8eab11737f436 --region us-east-1
```

**Deploy latest image**
```
sudo /opt/weightloss/deploy.sh          # without DB schema changes
sudo /opt/weightloss/deploy.sh migrate  # with Prisma migrations
```

**Check app health**
```
curl -s http://localhost/v1/ready
curl -s http://localhost/healthz   # nginx health endpoint
```

**Tail container logs**
```
sudo docker logs -f weightloss-api-1
```
(or view CloudWatch Logs `/weightloss/api`)

**Run DB seed (destroys existing data!)**
```
sudo docker run --rm --env-file /opt/weightloss/.env \
  -v /opt/weightloss/tsconfig.json:/app/tsconfig.json \
  851725402279.dkr.ecr.us-east-1.amazonaws.com/weight-loss-clinic-api:latest \
  npm run db:seed
```

**Run migrations only**
```
sudo docker run --rm --env-file /opt/weightloss/.env \
  851725402279.dkr.ecr.us-east-1.amazonaws.com/weight-loss-clinic-api:latest \
  npx prisma migrate deploy
```

**Update `.env`** (example using here-doc)
```
aws ssm send-command \
  --document-name AWS-RunShellScript \
  --instance-ids i-0f9d8eab11737f436 \
  --comment "Update env" \
  --parameters commands='["cat <<\'EOF\' | sudo tee /opt/weightloss/.env >/dev/null","...new env contents...","EOF"]'
```
Then `sudo /opt/weightloss/deploy.sh` to apply.

**Check RDS login (from local machine)**
```
psql "postgresql://weightloss_admin:<password>@weight-loss-db.cerwwea2qjz1.us-east-1.rds.amazonaws.com:5432/weightloss?sslmode=require"
```

---
## 15. Credentials & Secrets to Rotate Soon
- `weightloss_admin / TempPass123!` – change to a strong password; update `.env` & Parameter Store.
- `JWT_ACCESS_SECRET` and `JWT_REFRESH_SECRET` – replace placeholder values.
- Gmail app password `mlpkuqnyiufnkbgj` – rotate or switch to Amazon SES to avoid Gmail throttling.
- Seed data credentials (admin/patient) are public; update in production once real users exist.

---
## 16. Summary Checklist for New Engineers
1. Confirm EC2 instance `i-0f9d8eab11737f436` is running.
2. Use SSM to access the server; avoid SSH.
3. Keep `/opt/weightloss/.env` and Parameter Store in sync when secrets change.
4. Use `/opt/weightloss/deploy.sh migrate` for schema updates; never run `prisma migrate reset` on prod.
5. Use `docker run ... npm run db:seed` only on empty databases (staging/dev).
6. Monitor CloudWatch log group `/weightloss/api` for errors.
7. If rebuilding, follow sections 2–4 to recreate infrastructure.
8. Plan to add HTTPS + SSH lockdown + SES as soon as possible.

This runbook captures every command executed so far and should serve as the
canonical reference for operating the Weight Loss Clinic backend on AWS.

---
## 17. Cost Analysis (Backend Only)

| Resource | Approx Monthly Cost |
| --- | --- |
| EC2 t4g.small + 20 GB gp3 EBS | ~$17 |
| RDS db.t4g.micro + 20 GB gp3 storage | ~$22 |
| CloudWatch Logs & SSM (within free tier) | ~$5 |
| **Total** | **~$44/mo** |

Notes:
- Costs exclude the Amplify frontend (billed separately) and any Route 53 zones or certificates.
- Adding TLS via ACM + ALB would increase costs by ~$20/mo. A NAT Gateway would add ~$33/mo (not used).
- CloudWatch costs stay low if log retention is managed (default indefinite). Set retention (e.g., 30 days) to cap storage fees.
- "Amazon VPC" charges are not part of Amplify. They usually come from backend VPC resources:
  - Public IPv4 hourly charge (for the EC2 public IP).
  - NAT gateway hourly + data processing charges (not used here).
  - VPC interface endpoints (only if created).
  To confirm the exact VPC usage types:
  ```
  aws ce get-cost-and-usage \
    --time-period Start=YYYY-MM-01,End=YYYY-MM-01 \
    --granularity MONTHLY \
    --metrics UnblendedCost \
    --group-by Type=DIMENSION,Key=USAGE_TYPE \
    --filter '{"Dimensions":{"Key":"SERVICE","Values":["Amazon Virtual Private Cloud"]}}'
  ```

---
